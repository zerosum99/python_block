{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 판다스 1 차원 Series\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시리즈 클래스에 있는 속성과 메소드 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T abs add add_prefix add_suffix agg aggregate align all any append apply argmax argmin argsort array as_blocks as_matrix asfreq asobject asof astype at at_time autocorr axes base between between_time bfill blocks bool cat clip clip_lower clip_upper combine combine_first compound compress convert_objects copy corr count cov cummax cummin cumprod cumsum data describe diff div divide divmod dot drop drop_duplicates droplevel dropna dt dtype dtypes duplicated empty eq equals ewm expanding factorize ffill fillna filter first first_valid_index flags floordiv from_array from_csv ftype ftypes ge get get_dtype_counts get_ftype_counts get_value get_values groupby gt hasnans head hist iat idxmax idxmin iloc imag index infer_objects interpolate is_copy is_monotonic is_monotonic_decreasing is_monotonic_increasing is_unique isin isna isnull item items itemsize iteritems ix keys kurt kurtosis last last_valid_index le loc lt mad map mask max mean median memory_usage min mod mode mul multiply name nbytes ndim ne nlargest nonzero notna notnull nsmallest nunique pct_change pipe plot pop pow prod product ptp put quantile radd rank ravel rdiv rdivmod real reindex reindex_axis reindex_like rename rename_axis reorder_levels repeat replace resample reset_index rfloordiv rmod rmul rolling round rpow rsub rtruediv sample searchsorted select sem set_axis set_value shape shift size skew slice_shift sort_index sort_values sparse squeeze std str strides sub subtract sum swapaxes swaplevel tail take timetuple to_clipboard to_csv to_dense to_dict to_excel to_frame to_hdf to_json to_latex to_list to_msgpack to_numpy to_period to_pickle to_sparse to_sql to_string to_timestamp to_xarray tolist transform transpose truediv truncate tshift tz_convert tz_localize unique unstack update valid value_counts values var view where xs "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for i in dir(pd.Series) :\n",
    "    if not i.startswith(\"_\") :\n",
    "        print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 넘파이 클래스에 없는 Series 클래스에 추가된 메소드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update sub tshift compound at_time bfill asobject notnull lt eq radd transform describe reindex_like drop_duplicates pop product align from_csv between skew to_clipboard memory_usage idxmin loc tail factorize dtypes rtruediv reorder_levels is_monotonic_increasing resample quantile sparse isin abs aggregate add rpow divide notna last_valid_index sample to_latex is_copy get_ftype_counts to_msgpack plot timetuple reindex_axis equals drop dt mode multiply convert_objects duplicated unique is_monotonic_decreasing select iteritems map index interpolate hist isnull mad reset_index sem to_csv median subtract bool le div first gt nunique to_numpy add_prefix rfloordiv get mod to_frame kurtosis truediv fillna to_excel name to_json asof rdiv rsub values divmod pow ewm keys rmod pipe slice_shift replace as_blocks to_pickle floordiv set_axis ne rdivmod between_time expanding iat rank is_monotonic cov as_matrix hasnans unstack isna ftypes ge blocks to_period diff str to_list apply to_hdf cat to_timestamp array filter rmul to_sql nsmallest tz_convert sort_values shift idxmax ftype add_suffix set_value last nlargest at rename_axis to_dict cummax rename head rolling infer_objects combine_first sort_index dropna items where groupby from_array empty reindex to_dense append mask asfreq to_string axes xs cummin agg to_sparse truncate get_dtype_counts iloc pct_change clip_upper first_valid_index get_value autocorr mul get_values valid swaplevel clip_lower to_xarray corr ix ffill droplevel combine tz_localize count is_unique value_counts kurt "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "nd = set(dir(np.ndarray))\n",
    "pd = set(dir(pd.Series))\n",
    "\n",
    "ser = pd - nd\n",
    "\n",
    "for i in ser :\n",
    "    if not i.startswith(\"_\") :\n",
    "        print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy와 동일한 메소드\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real dtype ptp mean dot view strides flags searchsorted prod var put astype ravel nbytes copy all itemsize swapaxes data argmax cumsum sum size shape ndim argsort transpose std repeat any max min imag tolist T argmin compress cumprod nonzero round item squeeze base take clip "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "nd_= set(dir(np.ndarray))\n",
    "pd_ = set(dir(pd.Series))\n",
    "\n",
    "ser = pd_ & nd\n",
    "\n",
    "for i in ser :\n",
    "    if not i.startswith(\"_\") :\n",
    "        print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프로퍼티 처리하는 속성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<property at 0x116289548>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<property at 0x116289728>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series.base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<property at 0x116ef7188>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1차원 생성 \n",
    "\n",
    "    data : 배열 형, dict 또는 스칼라 값, 시리즈에 저장된 데이터 포함\n",
    "    색인 : 배열과 유사하거나 색인 (1d)\n",
    "            값은 해시 가능해야하며 데이터와 길이가 같아야합니다. 고유하지 않은 색인 값이 허용됩니다. 제공되지 않을 경우\n",
    "            RangeIndex (len (data))를 기본값으로 사용합니다. dict 및 인덱스 시퀀스가 모두 사용되면 인덱스는 dict에있는\n",
    "            키를 재정의합니다.\n",
    "    dtype : numpy.dtype 또는 없음  None이면 dtype이 유추됩니다.\n",
    "    copy : 부울, 기본값 False     입력 데이터 복사\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "obj = pd.Series([1,2,3,4])\n",
    "print(obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data 속성을 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dahlmoon/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Series.data is deprecated and will be removed in a future version\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<memory at 0x117327648>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dahlmoon/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Series.data is deprecated and will be removed in a future version\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.data.obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 내부의 속성과 메소드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_contiguous\n",
      "cast\n",
      "contiguous\n",
      "f_contiguous\n",
      "format\n",
      "hex\n",
      "itemsize\n",
      "nbytes\n",
      "ndim\n",
      "obj\n",
      "readonly\n",
      "release\n",
      "shape\n",
      "strides\n",
      "suboffsets\n",
      "tobytes\n",
      "tolist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dahlmoon/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Series.data is deprecated and will be removed in a future version\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "for i in dir(obj.data) :\n",
    "    if not i.startswith(\"_\") :\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실제 시리즈의 속성 알아보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실제 ndarray를 관리하는 속성  values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(obj.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실제 시리즈의 인덱스와 값이 가진 데이터 타입을 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=4, step=1)\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(obj.index)\n",
    "print(obj.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시리즈 생성할 때 데이터를 넣는 방법\n",
    "\n",
    "    시리즈는 명시적인 인덱스와 값이 매핑되는 구조이다. 그래서 딕셔너리로 넣으면 키는 인덱스로 값은 데이터로 들어간다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인덱스와 값을 같이 넣기 \n",
    "\n",
    "    dict 타입으로 지정해서 자동 인덱스 처리 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "Name: something, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "d = {'a':1,'b':2,'c':3}\n",
    "s3 = pd.Series(d,name='something')\n",
    "\n",
    "print(s3.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a', 'b', 'c'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'something'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리스트 자료형으로 자료 넣어 생성하기\n",
    "\n",
    "    리스트를 넣어서 시리즈를 생성하면 인덱스는 정수로 구성된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    d\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = ['a','b','c','d']\n",
    "obj1 = pd.Series(data) \n",
    "\n",
    "print(obj1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원소 하나를 검색은 인덱싱으로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print(obj1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인덱스를 리스트로 만들고 데이터도 리스트로 넣어서  생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: test, dtype: int64\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "index = ['a','b','c','d']\n",
    "obj1 = pd.Series([1,2,3,4],index=index,name=\"test\") \n",
    "\n",
    "print(obj1)\n",
    "print(obj1['a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy 연계 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.58520882  0.6331148   0.48355888 -0.02005357  1.52088916]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(np.random.randn(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998107\n",
      "1    0.216166\n",
      "2    0.210014\n",
      "3    0.069805\n",
      "4   -1.133587\n",
      "dtype: float64 <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(np.random.randn(5))\n",
    "\n",
    "print(s, type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a   -0.049085\n",
      "b   -1.178861\n",
      "c   -1.924115\n",
      "d    1.081869\n",
      "e    0.013337\n",
      "dtype: float64 <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "s1 = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "print(s1, type(s1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시리즈 속성 알아보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 속성  : 넘파이와 동일한 속성\n",
    "\n",
    "\n",
    "    \n",
    "     base\t    return the base object if the memory of the underlying data is blocks Internal property,\n",
    "                property synonym for as_blocks()\n",
    "     data\t     return the data pointer of the underlying data\n",
    "    dtype\t    return the dtype object of the underlying data\n",
    "    dtypes\t    return the dtype object of the underlying data\n",
    "    imag\t\n",
    "    itemsize    return the size of the dtype of the item of the underlying data\n",
    "    nbytes\t    return the number of bytes in the underlying data\n",
    "    ndim\t    return the number of dimensions of the underlying data,\n",
    "    real\t\n",
    "       T\t    return the transpose, which is by definition self\n",
    "    shape\t     return a tuple of the shape of the underlying data\n",
    "    size\t    return the number of elements in the underlying data\n",
    "    strides\t    return the strides of the underlying data\n",
    "    values\t    Return Series as ndarray or ndarray-like\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원과 모양을 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "obj = pd.Series([1,2,3,4],name=\"obj\")\n",
    "\n",
    "print(obj.ndim)\n",
    "print(obj.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 슬라이싱을 이용해서 처리하면 새로운 사본이 만들어지는 것이 아니라 원본의 참조를 가지고 간다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = obj[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### base 속성을 확인하면 실제 만들어진 시리즈의 values에 있는 객체와 동일하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dahlmoon/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.base is obj.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시리즈이 이름을 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'obj'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 내의 하나의 원소 길이와 전체 길이 그리고 확장할 때 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "8\n",
      "32\n",
      "(8,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dahlmoon/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Series.itemsize is deprecated and will be removed in a future version\n",
      "  \n",
      "/Users/dahlmoon/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Series.strides is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "print(obj.dtype)\n",
    "print(obj.itemsize)\n",
    "print(obj.nbytes)\n",
    "print(obj.strides)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실제 데이터를 접근할 수 있는 뷰 제공 속성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "Name: obj, dtype: int64\n",
      "{'int64': 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "Name: obj, dtype: int64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dahlmoon/anaconda/lib/python3.7/site-packages/pandas/core/generic.py:5569: FutureWarning: as_blocks is deprecated and will be removed in a future version\n",
      "  return self.as_blocks()\n"
     ]
    }
   ],
   "source": [
    "print(obj.values)\n",
    "print(obj.T)\n",
    "print(obj.blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  blocks 속성에 대한 내부 정보\n",
    "\n",
    "    blocks 내부에는 하나의 타입을 키로해서 기존에 들어간 데이터가 값으로 구성된 딕셔너리를 볼 수 있다. 이 블럭의 정보를 조회해 보겠다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'int64': 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "Name: test, dtype: int64}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "obj1 = pd.Series([1,2,3,4],name=\"test\")\n",
    " \n",
    "print(obj1.blocks)\n",
    "print(type(obj1.blocks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Int64Index([0, 1, 2, 3], dtype='int64')\n",
      "[1 2 3 4]\n",
      "test\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(type(obj1.blocks['int64']))\n",
    "print(obj1.blocks['int64'].index)\n",
    "print(obj1.blocks['int64'].values)\n",
    "print(obj1.blocks['int64'].name)\n",
    "print(obj1.blocks['int64'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인덱스에도 레벨링이 가능하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiindex 로 생성 \n",
    "\n",
    "   인덱스를 여러 개 필요할 경우 처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first  second\n",
      "bar    one      -1.866478\n",
      "       two      -0.155941\n",
      "baz    one       0.734725\n",
      "       two      -0.614719\n",
      "foo    one      -0.073881\n",
      "       two      -1.204987\n",
      "qux    one       1.799147\n",
      "       two      -0.287918\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],\n",
    "           ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n",
    "           \n",
    "tuples = list(zip(*arrays))\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "\n",
    "s = pd.Series(np.random.randn(8), index=index)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### level과 labels 이해하기\n",
    "\n",
    "    levels는 인덱스 계층구조에 있는 인덱스의 명칭을 표시한다.\n",
    "    labels는 실제 인덱스가 어떻게 계층화되어 있는 지를 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex(levels=[['bar', 'baz', 'foo', 'qux'], ['one', 'two']],\n",
       "           codes=[[0, 0, 1, 1, 2, 2, 3, 3], [0, 1, 0, 1, 0, 1, 0, 1]],\n",
       "           names=['first', 'second'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 판다스는 열단위로 처리하므로 행단위 처리를 위한 속성을 알아본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 속성  : pandas 추가 속성 \n",
    "\n",
    "    asobject\treturn object Series which contains boxed values\n",
    "    at\t        Fast label-based scalar accessor\n",
    "    axes\t    Return a list of the row axis labels\n",
    "    empty\t\n",
    "    flags\t\n",
    "    ftype\t    return if the data is sparse|dense\n",
    "    ftypes\t    return if the data is sparse|dense\n",
    "    hasnans\t\n",
    "    iat  \t    Fast integer location scalar accessor.\n",
    "    iloc\t    Purely integer-location based indexing for selection by position.\n",
    "    is_copy\t\n",
    "    is_monotonic\t          Return boolean if values in the object are\n",
    "    is_monotonic_decreasing\t  Return boolean if values in the object are\n",
    "    is_monotonic_increasing\t  Return boolean if values in the object are\n",
    "    is_unique\t              Return boolean if values in the object are unique\n",
    "   \n",
    "    ix\t        A primarily label-location based indexer, with integer position fallback.\n",
    "    loc\t        Purely label-location based indexer for selection by label.\n",
    "    name\t\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  내부 속성이 아무것도 없을 때 체크하는 법 : empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "obj_emp = pd.Series()\n",
    "print(obj_emp.empty)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가적인 인덱스 처리하는 뷰 속성\n",
    "\n",
    "    이 속성들이 특징은 명시적인 인덱스를 사용할 수도 있고 암묵적인 인덱스를 사용할 수 있다.\n",
    "    그래서 정수로 인덱스를 할 경우 명시적인 것인지 암묵적인 것인지에 대해 명확히 이해하고 있어야 한다.\n",
    "    \n",
    "    시리즈는 1차원이기 때문에 행으로 접근하나 열로 접근하나 동일하게 처리한다. \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  시리즈를 생성한 후에 인덱스를 할당하기.\n",
    "\n",
    "    인덱스는 불변이므로 내부의 원소는 갱신이 되지 않지만 새로운 객체로 대체가 가능하다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "obj1 = pd.Series([1,2,3,4],name=\"test\") \n",
    "\n",
    "obj1.index = ['a','b','c','d']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj1.index[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인덱스는 변경되지 않으므로 이를 갱신하면 __setitem__이 갱신메소드인데 내부에서 예외만 처리한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index does not support mutable operations\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    obj1.index[0] = 'z'\n",
    "except Exception as e :\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주요 Series 인스턴스의 값을 접근하기 위해 at은 원소의 값, loc는 슬라이싱 처리를 포함해서 검색, ix는 값을 검색 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(obj1.at['a'])\n",
    "print(obj1.iat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "Name: obj, dtype: int64\n",
      "Series([], Name: obj, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(obj.iloc[0:3])\n",
    "print(obj.loc['a':'c'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'> True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dahlmoon/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(type(obj1.ix['a']),obj1.ix['a'] == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 원소의 개수는 size, axes는 실제 인덱스에 대한 정보를 리스트로 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "int64:dense\n",
      "[RangeIndex(start=0, stop=4, step=1)]\n"
     ]
    }
   ],
   "source": [
    "print(obj.size)\n",
    "print(obj.ftypes)\n",
    "print(obj.axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인덱스 및 Series 이름 부여\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s3 = pd.Series([4, 5, 6], index=['a','b','c'], name=\"Series Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['a', 'b', 'c'], dtype='object')\n",
      "[4 5 6]\n",
      "Series Data\n"
     ]
    }
   ],
   "source": [
    "print(s3.index)\n",
    "print(s3.values)\n",
    "print(s3.name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "1\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "print(s3.dtype)\n",
    "print(s3.ndim)\n",
    "print(s3.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### index 이름 변경 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "dtype: int64\n",
      "alpha\n",
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj = pd.Series(d)\n",
    "print(obj)\n",
    "obj.index.name = 'alpha'\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터는 기본적으로 view 체계로 구성\n",
    "\n",
    "    기본적으로 대량 처리 계산을 위해서 기본으로 view를 제공한다.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 슬라이스로 새로운 변수에 할당을 했지만 실제 원본이 복사가 되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    999\n",
      "1      2\n",
      "2      3\n",
      "3      4\n",
      "dtype: int64\n",
      "0    999\n",
      "1      2\n",
      "2      3\n",
      "3      4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "obj1 = pd.Series([1,2,3,4])\n",
    "obj2 = obj1[:]\n",
    "\n",
    "obj2[0] = 999\n",
    "\n",
    "print(obj1)\n",
    "print(obj2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동일한 메모리에 있는 데이터를 참조하는 지를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[999   2   3   4]\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dahlmoon/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(obj2.base)\n",
    "\n",
    "print(np.may_share_memory(obj1,obj2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 새롭게 생성하면 실제 base 속성에는 아무것도 없다. 만들어진 시리즈는 원본이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s3 = pd.Series([4, 5, 6], index=['a','b','c'], name=\"Series Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "int64:dense\n",
      "[Index(['a', 'b', 'c'], dtype='object')]\n"
     ]
    }
   ],
   "source": [
    "print(s3.size)\n",
    "print(s3.ftypes)\n",
    "print(s3.axes)\n",
    "print(s3.empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시리즈를 가지고 행렬연산을 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'int64': a    4\n",
      "b    5\n",
      "c    6\n",
      "Name: Series Data, dtype: int64}\n",
      "a    4\n",
      "b    5\n",
      "c    6\n",
      "Name: Series Data, dtype: int64\n",
      "77\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "s3 = pd.Series([4, 5, 6], index=['a','b','c'], name=\"Series Data\")\n",
    "\n",
    "print(s3.blocks)\n",
    "print(s3.T)\n",
    "\n",
    "print(np.dot(s3,s3.T))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  특정 위치를 index 속성으로 조회 : loc\n",
    "\n",
    "    판다스의 데이터프레임은 열을 중심으로 검색하므로 실제 행 중심으로 검색할 때 많이 사용된다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _LocIndexer in module pandas.core.indexing object:\n",
      "\n",
      "class _LocIndexer(_LocationIndexer)\n",
      " |  Access a group of rows and columns by label(s) or a boolean array.\n",
      " |  \n",
      " |  ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |  boolean array.\n",
      " |  \n",
      " |  Allowed inputs are:\n",
      " |  \n",
      " |  - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |    interpreted as a *label* of the index, and **never** as an\n",
      " |    integer position along the index).\n",
      " |  - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |  - A slice object with labels, e.g. ``'a':'f'``.\n",
      " |  \n",
      " |    .. warning:: Note that contrary to usual python slices, **both** the\n",
      " |        start and the stop are included\n",
      " |  \n",
      " |  - A boolean array of the same length as the axis being sliced,\n",
      " |    e.g. ``[True, False, True]``.\n",
      " |  - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |    or Panel) and that returns valid output for indexing (one of the above)\n",
      " |  \n",
      " |  See more at :ref:`Selection by Label <indexing.label>`\n",
      " |  \n",
      " |  Raises\n",
      " |  ------\n",
      " |  KeyError:\n",
      " |      when any items are not found\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  DataFrame.at : Access a single value for a row/column label pair.\n",
      " |  DataFrame.iloc : Access group of rows and columns by integer position(s).\n",
      " |  DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n",
      " |      Series/DataFrame.\n",
      " |  Series.loc : Access group of values using labels.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  **Getting values**\n",
      " |  \n",
      " |  >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |  ...      index=['cobra', 'viper', 'sidewinder'],\n",
      " |  ...      columns=['max_speed', 'shield'])\n",
      " |  >>> df\n",
      " |              max_speed  shield\n",
      " |  cobra               1       2\n",
      " |  viper               4       5\n",
      " |  sidewinder          7       8\n",
      " |  \n",
      " |  Single label. Note this returns the row as a Series.\n",
      " |  \n",
      " |  >>> df.loc['viper']\n",
      " |  max_speed    4\n",
      " |  shield       5\n",
      " |  Name: viper, dtype: int64\n",
      " |  \n",
      " |  List of labels. Note using ``[[]]`` returns a DataFrame.\n",
      " |  \n",
      " |  >>> df.loc[['viper', 'sidewinder']]\n",
      " |              max_speed  shield\n",
      " |  viper               4       5\n",
      " |  sidewinder          7       8\n",
      " |  \n",
      " |  Single label for row and column\n",
      " |  \n",
      " |  >>> df.loc['cobra', 'shield']\n",
      " |  2\n",
      " |  \n",
      " |  Slice with labels for row and single label for column. As mentioned\n",
      " |  above, note that both the start and stop of the slice are included.\n",
      " |  \n",
      " |  >>> df.loc['cobra':'viper', 'max_speed']\n",
      " |  cobra    1\n",
      " |  viper    4\n",
      " |  Name: max_speed, dtype: int64\n",
      " |  \n",
      " |  Boolean list with the same length as the row axis\n",
      " |  \n",
      " |  >>> df.loc[[False, False, True]]\n",
      " |              max_speed  shield\n",
      " |  sidewinder          7       8\n",
      " |  \n",
      " |  Conditional that returns a boolean Series\n",
      " |  \n",
      " |  >>> df.loc[df['shield'] > 6]\n",
      " |              max_speed  shield\n",
      " |  sidewinder          7       8\n",
      " |  \n",
      " |  Conditional that returns a boolean Series with column labels specified\n",
      " |  \n",
      " |  >>> df.loc[df['shield'] > 6, ['max_speed']]\n",
      " |              max_speed\n",
      " |  sidewinder          7\n",
      " |  \n",
      " |  Callable that returns a boolean Series\n",
      " |  \n",
      " |  >>> df.loc[lambda df: df['shield'] == 8]\n",
      " |              max_speed  shield\n",
      " |  sidewinder          7       8\n",
      " |  \n",
      " |  **Setting values**\n",
      " |  \n",
      " |  Set value for all items matching the list of labels\n",
      " |  \n",
      " |  >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
      " |  >>> df\n",
      " |              max_speed  shield\n",
      " |  cobra               1       2\n",
      " |  viper               4      50\n",
      " |  sidewinder          7      50\n",
      " |  \n",
      " |  Set value for an entire row\n",
      " |  \n",
      " |  >>> df.loc['cobra'] = 10\n",
      " |  >>> df\n",
      " |              max_speed  shield\n",
      " |  cobra              10      10\n",
      " |  viper               4      50\n",
      " |  sidewinder          7      50\n",
      " |  \n",
      " |  Set value for an entire column\n",
      " |  \n",
      " |  >>> df.loc[:, 'max_speed'] = 30\n",
      " |  >>> df\n",
      " |              max_speed  shield\n",
      " |  cobra              30      10\n",
      " |  viper              30      50\n",
      " |  sidewinder         30      50\n",
      " |  \n",
      " |  Set value for rows matching callable condition\n",
      " |  \n",
      " |  >>> df.loc[df['shield'] > 35] = 0\n",
      " |  >>> df\n",
      " |              max_speed  shield\n",
      " |  cobra              30      10\n",
      " |  viper               0       0\n",
      " |  sidewinder          0       0\n",
      " |  \n",
      " |  **Getting values on a DataFrame with an index that has integer labels**\n",
      " |  \n",
      " |  Another example using integers for the index\n",
      " |  \n",
      " |  >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |  ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
      " |  >>> df\n",
      " |     max_speed  shield\n",
      " |  7          1       2\n",
      " |  8          4       5\n",
      " |  9          7       8\n",
      " |  \n",
      " |  Slice with integer labels for rows. As mentioned above, note that both\n",
      " |  the start and stop of the slice are included.\n",
      " |  \n",
      " |  >>> df.loc[7:9]\n",
      " |     max_speed  shield\n",
      " |  7          1       2\n",
      " |  8          4       5\n",
      " |  9          7       8\n",
      " |  \n",
      " |  **Getting values with a MultiIndex**\n",
      " |  \n",
      " |  A number of examples using a DataFrame with a MultiIndex\n",
      " |  \n",
      " |  >>> tuples = [\n",
      " |  ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
      " |  ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
      " |  ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n",
      " |  ... ]\n",
      " |  >>> index = pd.MultiIndex.from_tuples(tuples)\n",
      " |  >>> values = [[12, 2], [0, 4], [10, 20],\n",
      " |  ...         [1, 4], [7, 1], [16, 36]]\n",
      " |  >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
      " |  >>> df\n",
      " |                       max_speed  shield\n",
      " |  cobra      mark i           12       2\n",
      " |             mark ii           0       4\n",
      " |  sidewinder mark i           10      20\n",
      " |             mark ii           1       4\n",
      " |  viper      mark ii           7       1\n",
      " |             mark iii         16      36\n",
      " |  \n",
      " |  Single label. Note this returns a DataFrame with a single index.\n",
      " |  \n",
      " |  >>> df.loc['cobra']\n",
      " |           max_speed  shield\n",
      " |  mark i          12       2\n",
      " |  mark ii          0       4\n",
      " |  \n",
      " |  Single index tuple. Note this returns a Series.\n",
      " |  \n",
      " |  >>> df.loc[('cobra', 'mark ii')]\n",
      " |  max_speed    0\n",
      " |  shield       4\n",
      " |  Name: (cobra, mark ii), dtype: int64\n",
      " |  \n",
      " |  Single label for row and column. Similar to passing in a tuple, this\n",
      " |  returns a Series.\n",
      " |  \n",
      " |  >>> df.loc['cobra', 'mark i']\n",
      " |  max_speed    12\n",
      " |  shield        2\n",
      " |  Name: (cobra, mark i), dtype: int64\n",
      " |  \n",
      " |  Single tuple. Note using ``[[]]`` returns a DataFrame.\n",
      " |  \n",
      " |  >>> df.loc[[('cobra', 'mark ii')]]\n",
      " |                 max_speed  shield\n",
      " |  cobra mark ii          0       4\n",
      " |  \n",
      " |  Single tuple for the index with a single label for the column\n",
      " |  \n",
      " |  >>> df.loc[('cobra', 'mark i'), 'shield']\n",
      " |  2\n",
      " |  \n",
      " |  Slice from index tuple to single label\n",
      " |  \n",
      " |  >>> df.loc[('cobra', 'mark i'):'viper']\n",
      " |                       max_speed  shield\n",
      " |  cobra      mark i           12       2\n",
      " |             mark ii           0       4\n",
      " |  sidewinder mark i           10      20\n",
      " |             mark ii           1       4\n",
      " |  viper      mark ii           7       1\n",
      " |             mark iii         16      36\n",
      " |  \n",
      " |  Slice from index tuple to index tuple\n",
      " |  \n",
      " |  >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n",
      " |                      max_speed  shield\n",
      " |  cobra      mark i          12       2\n",
      " |             mark ii          0       4\n",
      " |  sidewinder mark i          10      20\n",
      " |             mark ii          1       4\n",
      " |  viper      mark ii          7       1\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      _LocIndexer\n",
      " |      _LocationIndexer\n",
      " |      _NDFrameIndexer\n",
      " |      pandas._libs.indexing._NDFrameIndexerBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods inherited from _LocationIndexer:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _NDFrameIndexer:\n",
      " |  \n",
      " |  __call__(self, axis=None)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _NDFrameIndexer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from _NDFrameIndexer:\n",
      " |  \n",
      " |  axis = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas._libs.indexing._NDFrameIndexerBase:\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __reduce__ = __reduce_cython__(...)\n",
      " |  \n",
      " |  __setstate__ = __setstate_cython__(...)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from pandas._libs.indexing._NDFrameIndexerBase:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas._libs.indexing._NDFrameIndexerBase:\n",
      " |  \n",
      " |  name\n",
      " |  \n",
      " |  ndim\n",
      " |  \n",
      " |  obj\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(s3.loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 명시적인 인덱스 정보를 가지고 검색한다. \n",
    "\n",
    "    인덱스는 항상 행을 나타낸다는 것을 알고있어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "a    4\n",
      "b    5\n",
      "dtype: int64\n",
      "<pandas.core.indexing._LocIndexer object at 0x117464138>\n",
      "a    4\n",
      "b    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "s1 = pd.Series([1, 2, 3])\n",
    "print(s1[0])\n",
    "\n",
    "s3 = pd.Series([4, 5, 6], index=['a','b','c'])\n",
    "print(s3[['a','b']])\n",
    "\n",
    "print(s3.loc)\n",
    "print(s3.loc[['a','b']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  인덱스 변경하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method reindex in module pandas.core.series:\n",
      "\n",
      "reindex(index=None, **kwargs) method of pandas.core.series.Series instance\n",
      "    Conform Series to new index with optional filling logic, placing\n",
      "    NA/NaN in locations having no value in the previous index. A new object\n",
      "    is produced unless the new index is equivalent to the current one and\n",
      "    ``copy=False``.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    \n",
      "    index : array-like, optional\n",
      "        New labels / index to conform to, should be specified using\n",
      "        keywords. Preferably an Index object to avoid duplicating data\n",
      "    \n",
      "    method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      "        Method to use for filling holes in reindexed DataFrame.\n",
      "        Please note: this is only applicable to DataFrames/Series with a\n",
      "        monotonically increasing/decreasing index.\n",
      "    \n",
      "        * None (default): don't fill gaps\n",
      "        * pad / ffill: propagate last valid observation forward to next\n",
      "          valid\n",
      "        * backfill / bfill: use next valid observation to fill gap\n",
      "        * nearest: use nearest valid observations to fill gap\n",
      "    \n",
      "    copy : bool, default True\n",
      "        Return a new object, even if the passed indexes are the same.\n",
      "    level : int or name\n",
      "        Broadcast across a level, matching Index values on the\n",
      "        passed MultiIndex level.\n",
      "    fill_value : scalar, default np.NaN\n",
      "        Value to use for missing values. Defaults to NaN, but can be any\n",
      "        \"compatible\" value.\n",
      "    limit : int, default None\n",
      "        Maximum number of consecutive elements to forward or backward fill.\n",
      "    tolerance : optional\n",
      "        Maximum distance between original and new labels for inexact\n",
      "        matches. The values of the index at the matching locations most\n",
      "        satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      "    \n",
      "        Tolerance may be a scalar value, which applies the same tolerance\n",
      "        to all values, or list-like, which applies variable tolerance per\n",
      "        element. List-like includes list, tuple, array, Series, and must be\n",
      "        the same size as the index and its dtype must exactly match the\n",
      "        index's type.\n",
      "    \n",
      "        .. versionadded:: 0.21.0 (list-like tolerance)\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Series with changed index.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.set_index : Set row labels.\n",
      "    DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      "    DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    ``DataFrame.reindex`` supports two calling conventions\n",
      "    \n",
      "    * ``(index=index_labels, columns=column_labels, ...)``\n",
      "    * ``(labels, axis={'index', 'columns'}, ...)``\n",
      "    \n",
      "    We *highly* recommend using keyword arguments to clarify your\n",
      "    intent.\n",
      "    \n",
      "    Create a dataframe with some fictional data.\n",
      "    \n",
      "    >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      "    >>> df = pd.DataFrame({\n",
      "    ...      'http_status': [200,200,404,404,301],\n",
      "    ...      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      "    ...       index=index)\n",
      "    >>> df\n",
      "               http_status  response_time\n",
      "    Firefox            200           0.04\n",
      "    Chrome             200           0.02\n",
      "    Safari             404           0.07\n",
      "    IE10               404           0.08\n",
      "    Konqueror          301           1.00\n",
      "    \n",
      "    Create a new index and reindex the dataframe. By default\n",
      "    values in the new index that do not have corresponding\n",
      "    records in the dataframe are assigned ``NaN``.\n",
      "    \n",
      "    >>> new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      "    ...             'Chrome']\n",
      "    >>> df.reindex(new_index)\n",
      "                   http_status  response_time\n",
      "    Safari               404.0           0.07\n",
      "    Iceweasel              NaN            NaN\n",
      "    Comodo Dragon          NaN            NaN\n",
      "    IE10                 404.0           0.08\n",
      "    Chrome               200.0           0.02\n",
      "    \n",
      "    We can fill in the missing values by passing a value to\n",
      "    the keyword ``fill_value``. Because the index is not monotonically\n",
      "    increasing or decreasing, we cannot use arguments to the keyword\n",
      "    ``method`` to fill the ``NaN`` values.\n",
      "    \n",
      "    >>> df.reindex(new_index, fill_value=0)\n",
      "                   http_status  response_time\n",
      "    Safari                 404           0.07\n",
      "    Iceweasel                0           0.00\n",
      "    Comodo Dragon            0           0.00\n",
      "    IE10                   404           0.08\n",
      "    Chrome                 200           0.02\n",
      "    \n",
      "    >>> df.reindex(new_index, fill_value='missing')\n",
      "                  http_status response_time\n",
      "    Safari                404          0.07\n",
      "    Iceweasel         missing       missing\n",
      "    Comodo Dragon     missing       missing\n",
      "    IE10                  404          0.08\n",
      "    Chrome                200          0.02\n",
      "    \n",
      "    We can also reindex the columns.\n",
      "    \n",
      "    >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      "               http_status  user_agent\n",
      "    Firefox            200         NaN\n",
      "    Chrome             200         NaN\n",
      "    Safari             404         NaN\n",
      "    IE10               404         NaN\n",
      "    Konqueror          301         NaN\n",
      "    \n",
      "    Or we can use \"axis-style\" keyword arguments\n",
      "    \n",
      "    >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      "               http_status  user_agent\n",
      "    Firefox            200         NaN\n",
      "    Chrome             200         NaN\n",
      "    Safari             404         NaN\n",
      "    IE10               404         NaN\n",
      "    Konqueror          301         NaN\n",
      "    \n",
      "    To further illustrate the filling functionality in\n",
      "    ``reindex``, we will create a dataframe with a\n",
      "    monotonically increasing index (for example, a sequence\n",
      "    of dates).\n",
      "    \n",
      "    >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      "    >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      "    ...                    index=date_index)\n",
      "    >>> df2\n",
      "                prices\n",
      "    2010-01-01   100.0\n",
      "    2010-01-02   101.0\n",
      "    2010-01-03     NaN\n",
      "    2010-01-04   100.0\n",
      "    2010-01-05    89.0\n",
      "    2010-01-06    88.0\n",
      "    \n",
      "    Suppose we decide to expand the dataframe to cover a wider\n",
      "    date range.\n",
      "    \n",
      "    >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      "    >>> df2.reindex(date_index2)\n",
      "                prices\n",
      "    2009-12-29     NaN\n",
      "    2009-12-30     NaN\n",
      "    2009-12-31     NaN\n",
      "    2010-01-01   100.0\n",
      "    2010-01-02   101.0\n",
      "    2010-01-03     NaN\n",
      "    2010-01-04   100.0\n",
      "    2010-01-05    89.0\n",
      "    2010-01-06    88.0\n",
      "    2010-01-07     NaN\n",
      "    \n",
      "    The index entries that did not have a value in the original data frame\n",
      "    (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      "    If desired, we can fill in the missing values using one of several\n",
      "    options.\n",
      "    \n",
      "    For example, to back-propagate the last valid value to fill the ``NaN``\n",
      "    values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      "    \n",
      "    >>> df2.reindex(date_index2, method='bfill')\n",
      "                prices\n",
      "    2009-12-29   100.0\n",
      "    2009-12-30   100.0\n",
      "    2009-12-31   100.0\n",
      "    2010-01-01   100.0\n",
      "    2010-01-02   101.0\n",
      "    2010-01-03     NaN\n",
      "    2010-01-04   100.0\n",
      "    2010-01-05    89.0\n",
      "    2010-01-06    88.0\n",
      "    2010-01-07     NaN\n",
      "    \n",
      "    Please note that the ``NaN`` value present in the original dataframe\n",
      "    (at index value 2010-01-03) will not be filled by any of the\n",
      "    value propagation schemes. This is because filling while reindexing\n",
      "    does not look at dataframe values, but only compares the original and\n",
      "    desired indexes. If you do want to fill in the ``NaN`` values present\n",
      "    in the original dataframe, use the ``fillna()`` method.\n",
      "    \n",
      "    See the :ref:`user guide <basics.reindexing>` for more.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(obj.reindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인덱스를 바꾸어서 재정렬해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    3\n",
      "2    5\n",
      "3    2\n",
      "4    4\n",
      "dtype: int64\n",
      "3    2\n",
      "2    5\n",
      "0    1\n",
      "1    3\n",
      "4    4\n",
      "dtype: int64\n",
      "0    2\n",
      "1    5\n",
      "2    1\n",
      "3    3\n",
      "4    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "obj = pd.Series([1,3,5,2,4])\n",
    "\n",
    "print(obj)\n",
    "obj1 = obj.reindex([3,2,0,1,4])\n",
    "print(obj1)\n",
    "\n",
    "obj1.index = [0,1,2,3,4]\n",
    "print(obj1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정렬 메소드 : sort_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "3    2\n",
      "1    3\n",
      "4    4\n",
      "2    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "obj = pd.Series([1,3,5,2,4])\n",
    "\n",
    "obj.sort_values(inplace=True)\n",
    "print(obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시리즈에 데이터 연결하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  두 개를 연결하기 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method append in module pandas.core.series:\n",
      "\n",
      "append(to_append, ignore_index=False, verify_integrity=False) method of pandas.core.series.Series instance\n",
      "    Concatenate two or more Series.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    to_append : Series or list/tuple of Series\n",
      "    ignore_index : boolean, default False\n",
      "        If True, do not use the index labels.\n",
      "    \n",
      "        .. versionadded:: 0.19.0\n",
      "    \n",
      "    verify_integrity : boolean, default False\n",
      "        If True, raise Exception on creating index with duplicates\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    appended : Series\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    concat : General function to concatenate DataFrame, Series\n",
      "        or Panel objects.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Iteratively appending to a Series can be more computationally intensive\n",
      "    than a single concatenate. A better solution is to append values to a\n",
      "    list and then concatenate the list with the original Series all at\n",
      "    once.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> s1 = pd.Series([1, 2, 3])\n",
      "    >>> s2 = pd.Series([4, 5, 6])\n",
      "    >>> s3 = pd.Series([4, 5, 6], index=[3,4,5])\n",
      "    >>> s1.append(s2)\n",
      "    0    1\n",
      "    1    2\n",
      "    2    3\n",
      "    0    4\n",
      "    1    5\n",
      "    2    6\n",
      "    dtype: int64\n",
      "    \n",
      "    >>> s1.append(s3)\n",
      "    0    1\n",
      "    1    2\n",
      "    2    3\n",
      "    3    4\n",
      "    4    5\n",
      "    5    6\n",
      "    dtype: int64\n",
      "    \n",
      "    With `ignore_index` set to True:\n",
      "    \n",
      "    >>> s1.append(s2, ignore_index=True)\n",
      "    0    1\n",
      "    1    2\n",
      "    2    3\n",
      "    3    4\n",
      "    4    5\n",
      "    5    6\n",
      "    dtype: int64\n",
      "    \n",
      "    With `verify_integrity` set to True:\n",
      "    \n",
      "    >>> s1.append(s2, verify_integrity=True)\n",
      "    Traceback (most recent call last):\n",
      "    ...\n",
      "    ValueError: Indexes have overlapping values: [0, 1, 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(obj.append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "0    4\n",
      "1    5\n",
      "2    6\n",
      "dtype: int64\n",
      "3    4\n",
      "4    5\n",
      "5    6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s1 = pd.Series([1, 2, 3])\n",
    "s2 = pd.Series([4, 5, 6])\n",
    "s3 = pd.Series([4, 5, 6], index=[3,4,5])\n",
    "s = s1.append(s2)\n",
    "print(s)\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연결할 때 인덱스는 기존 것을 그대로 처리된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    3\n",
      "2    5\n",
      "3    2\n",
      "4    4\n",
      "0    1\n",
      "1    3\n",
      "2    5\n",
      "3    2\n",
      "4    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "obj = pd.Series([1,3,5,2,4])\n",
    "\n",
    "obj1 = pd.Series([1,3,5,2,4])\n",
    "\n",
    "obj2 = obj.append(obj1)\n",
    "print(obj2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인덱스를 대체하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2, 3, 4, 0, 1, 2, 3, 4], dtype='int64')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.index = pd.RangeIndex(start=0, stop=10, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=10, step=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    3\n",
       "2    5\n",
       "3    2\n",
       "4    4\n",
       "5    1\n",
       "6    3\n",
       "7    5\n",
       "8    2\n",
       "9    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원소가 문자열일 경우 split 처리하기\n",
    "\n",
    "    원소의 내부가 문자열로 되어있을 경우 str을 이용해서 내부의 문자열을 분리할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  문자열을 분리하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Hello world\n",
      "1    Python pandas\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "obj = pd.Series(['Hello world', 'Python pandas'])\n",
    "print(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.strings.StringMethods at 0x11743a320>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [Hello, world]\n",
      "1    [Python, pandas]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(obj.str.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원소 내의  널값 확인 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인덱스를 다르게 줄 경우 내부에 널값이 들어감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    NaN\n",
      "b    2.0\n",
      "c    3.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj = pd.Series(d,index=['A','b','c'])\n",
    "print(obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 널값을 확인하는 함수를 이용해서 처리하면 불린 값으로 결과를 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A     True\n",
      "b    False\n",
      "c    False\n",
      "dtype: bool\n",
      "A    False\n",
      "b     True\n",
      "c     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(pd.isnull(obj))\n",
    "print(pd.notnull(obj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특정 속성을 가지고 원소 검색하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### at 속성으로 값 가져오기 : 명기적으로 처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: series, dtype: int64\n",
      "{}\n",
      "1\n",
      "at\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj = pd.Series(d, name=\"series\")\n",
    "print(obj)\n",
    "print(obj.at.__dict__)\n",
    "print(obj.at.ndim)\n",
    "print(obj.at.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(obj['a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iat로 암묵적 인덱스로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: series, dtype: int64\n",
      "{}\n",
      "1\n",
      "iat\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj = pd.Series(d, name=\"series\")\n",
    "print(obj)\n",
    "print(obj.iat.__dict__)\n",
    "print(obj.iat.ndim)\n",
    "print(obj.iat.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(obj.iat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loc 명시적 데이터 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: series, dtype: int64\n",
      "{}\n",
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "Name: series, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj = pd.Series(d, name=\"series\")\n",
    "print(obj)\n",
    "print(obj.loc.__dict__)\n",
    "\n",
    "print(obj.loc['a':'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iloc 암묵적 데이터 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "Name: series, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'a':1, 'b':2, 'c':3, 'd':4}\n",
    "\n",
    "obj = pd.Series(d, name=\"series\")\n",
    "print(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "a    1\n",
      "b    2\n",
      "Name: series, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(obj.iloc.__dict__)\n",
    "\n",
    "print(obj.iloc[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index 클래스 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__inv__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmul__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_accessors',\n",
       " '_add_comparison_methods',\n",
       " '_add_logical_methods',\n",
       " '_add_logical_methods_disabled',\n",
       " '_add_numeric_methods',\n",
       " '_add_numeric_methods_add_sub_disabled',\n",
       " '_add_numeric_methods_binary',\n",
       " '_add_numeric_methods_disabled',\n",
       " '_add_numeric_methods_unary',\n",
       " '_assert_can_do_op',\n",
       " '_assert_can_do_setop',\n",
       " '_assert_take_fillable',\n",
       " '_attributes',\n",
       " '_can_hold_identifiers_and_holds_name',\n",
       " '_can_hold_na',\n",
       " '_can_reindex',\n",
       " '_cleanup',\n",
       " '_coerce_scalar_to_index',\n",
       " '_coerce_to_ndarray',\n",
       " '_comparables',\n",
       " '_concat',\n",
       " '_concat_same_dtype',\n",
       " '_constructor',\n",
       " '_convert_arr_indexer',\n",
       " '_convert_can_do_setop',\n",
       " '_convert_for_op',\n",
       " '_convert_index_indexer',\n",
       " '_convert_list_indexer',\n",
       " '_convert_listlike_indexer',\n",
       " '_convert_scalar_indexer',\n",
       " '_convert_slice_indexer',\n",
       " '_convert_tolerance',\n",
       " '_data',\n",
       " '_defer_to_indexing',\n",
       " '_deprecations',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_engine',\n",
       " '_engine_type',\n",
       " '_evaluate_with_datetime_like',\n",
       " '_evaluate_with_timedelta_like',\n",
       " '_filter_indexer_tolerance',\n",
       " '_format_attrs',\n",
       " '_format_data',\n",
       " '_format_native_types',\n",
       " '_format_space',\n",
       " '_format_with_header',\n",
       " '_formatter_func',\n",
       " '_get_attributes_dict',\n",
       " '_get_fill_indexer',\n",
       " '_get_fill_indexer_searchsorted',\n",
       " '_get_grouper_for_level',\n",
       " '_get_level_number',\n",
       " '_get_level_values',\n",
       " '_get_loc_only_exact_matches',\n",
       " '_get_names',\n",
       " '_get_nearest_indexer',\n",
       " '_get_reconciled_name_object',\n",
       " '_get_string_slice',\n",
       " '_get_unique_index',\n",
       " '_has_complex_internals',\n",
       " '_id',\n",
       " '_infer_as_myclass',\n",
       " '_inner_indexer',\n",
       " '_invalid_indexer',\n",
       " '_is_homogeneous_type',\n",
       " '_is_memory_usage_qualified',\n",
       " '_is_numeric_dtype',\n",
       " '_is_strictly_monotonic_decreasing',\n",
       " '_is_strictly_monotonic_increasing',\n",
       " '_isnan',\n",
       " '_join_level',\n",
       " '_join_monotonic',\n",
       " '_join_multi',\n",
       " '_join_non_unique',\n",
       " '_join_precedence',\n",
       " '_left_indexer',\n",
       " '_left_indexer_unique',\n",
       " '_map_values',\n",
       " '_maybe_cast_indexer',\n",
       " '_maybe_cast_slice_bound',\n",
       " '_maybe_promote',\n",
       " '_maybe_update_attributes',\n",
       " '_mpl_repr',\n",
       " '_na_value',\n",
       " '_nan_idxs',\n",
       " '_ndarray_values',\n",
       " '_outer_indexer',\n",
       " '_reduce',\n",
       " '_reindex_non_unique',\n",
       " '_reset_cache',\n",
       " '_reset_identity',\n",
       " '_scalar_data_error',\n",
       " '_searchsorted_monotonic',\n",
       " '_set_names',\n",
       " '_shallow_copy',\n",
       " '_shallow_copy_with_infer',\n",
       " '_simple_new',\n",
       " '_sort_levels_monotonic',\n",
       " '_string_data_error',\n",
       " '_summary',\n",
       " '_to_safe_for_reshape',\n",
       " '_try_convert_to_int_index',\n",
       " '_typ',\n",
       " '_unpickle_compat',\n",
       " '_update_inplace',\n",
       " '_validate_for_numeric_binop',\n",
       " '_validate_for_numeric_unaryop',\n",
       " '_validate_index_level',\n",
       " '_validate_indexer',\n",
       " '_validate_names',\n",
       " '_validate_sort_keyword',\n",
       " '_values',\n",
       " '_wrap_joined_index',\n",
       " '_wrap_setop_result',\n",
       " 'all',\n",
       " 'any',\n",
       " 'append',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'array',\n",
       " 'asi8',\n",
       " 'asof',\n",
       " 'asof_locs',\n",
       " 'astype',\n",
       " 'base',\n",
       " 'contains',\n",
       " 'copy',\n",
       " 'data',\n",
       " 'delete',\n",
       " 'difference',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'droplevel',\n",
       " 'dropna',\n",
       " 'dtype',\n",
       " 'dtype_str',\n",
       " 'duplicated',\n",
       " 'empty',\n",
       " 'equals',\n",
       " 'factorize',\n",
       " 'fillna',\n",
       " 'flags',\n",
       " 'format',\n",
       " 'get_duplicates',\n",
       " 'get_indexer',\n",
       " 'get_indexer_for',\n",
       " 'get_indexer_non_unique',\n",
       " 'get_level_values',\n",
       " 'get_loc',\n",
       " 'get_slice_bound',\n",
       " 'get_value',\n",
       " 'get_values',\n",
       " 'groupby',\n",
       " 'has_duplicates',\n",
       " 'hasnans',\n",
       " 'holds_integer',\n",
       " 'identical',\n",
       " 'inferred_type',\n",
       " 'insert',\n",
       " 'intersection',\n",
       " 'is_',\n",
       " 'is_all_dates',\n",
       " 'is_boolean',\n",
       " 'is_categorical',\n",
       " 'is_floating',\n",
       " 'is_integer',\n",
       " 'is_interval',\n",
       " 'is_lexsorted_for_tuple',\n",
       " 'is_mixed',\n",
       " 'is_monotonic',\n",
       " 'is_monotonic_decreasing',\n",
       " 'is_monotonic_increasing',\n",
       " 'is_numeric',\n",
       " 'is_object',\n",
       " 'is_type_compatible',\n",
       " 'is_unique',\n",
       " 'isin',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'item',\n",
       " 'itemsize',\n",
       " 'join',\n",
       " 'map',\n",
       " 'max',\n",
       " 'memory_usage',\n",
       " 'min',\n",
       " 'name',\n",
       " 'names',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'nlevels',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'nunique',\n",
       " 'putmask',\n",
       " 'ravel',\n",
       " 'reindex',\n",
       " 'rename',\n",
       " 'repeat',\n",
       " 'searchsorted',\n",
       " 'set_names',\n",
       " 'set_value',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'slice_indexer',\n",
       " 'slice_locs',\n",
       " 'sort',\n",
       " 'sort_values',\n",
       " 'sortlevel',\n",
       " 'str',\n",
       " 'strides',\n",
       " 'summary',\n",
       " 'symmetric_difference',\n",
       " 'take',\n",
       " 'to_flat_index',\n",
       " 'to_frame',\n",
       " 'to_list',\n",
       " 'to_native_types',\n",
       " 'to_numpy',\n",
       " 'to_series',\n",
       " 'tolist',\n",
       " 'transpose',\n",
       " 'union',\n",
       " 'unique',\n",
       " 'value_counts',\n",
       " 'values',\n",
       " 'view',\n",
       " 'where']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pd.Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인덱스 클래스의 속성 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x label\n",
      "['xa' 'xb' 'xc']\n",
      "object\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x = pd.Index(['xa','xb','xc'], name=\"x label\")\n",
    "\n",
    "print(x.name)\n",
    "print(x.values)\n",
    "print(x.dtype)\n",
    "print(x.ndim)\n",
    "print(x.nlevels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 날짜로 범위 정하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function date_range in module pandas.core.indexes.datetimes:\n",
      "\n",
      "date_range(start=None, end=None, periods=None, freq=None, tz=None, normalize=False, name=None, closed=None, **kwargs)\n",
      "    Return a fixed frequency DatetimeIndex.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    start : str or datetime-like, optional\n",
      "        Left bound for generating dates.\n",
      "    end : str or datetime-like, optional\n",
      "        Right bound for generating dates.\n",
      "    periods : integer, optional\n",
      "        Number of periods to generate.\n",
      "    freq : str or DateOffset, default 'D'\n",
      "        Frequency strings can have multiples, e.g. '5H'. See\n",
      "        :ref:`here <timeseries.offset_aliases>` for a list of\n",
      "        frequency aliases.\n",
      "    tz : str or tzinfo, optional\n",
      "        Time zone name for returning localized DatetimeIndex, for example\n",
      "        'Asia/Hong_Kong'. By default, the resulting DatetimeIndex is\n",
      "        timezone-naive.\n",
      "    normalize : bool, default False\n",
      "        Normalize start/end dates to midnight before generating date range.\n",
      "    name : str, default None\n",
      "        Name of the resulting DatetimeIndex.\n",
      "    closed : {None, 'left', 'right'}, optional\n",
      "        Make the interval closed with respect to the given frequency to\n",
      "        the 'left', 'right', or both sides (None, the default).\n",
      "    **kwargs\n",
      "        For compatibility. Has no effect on the result.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    rng : DatetimeIndex\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    pandas.DatetimeIndex : An immutable container for datetimes.\n",
      "    pandas.timedelta_range : Return a fixed frequency TimedeltaIndex.\n",
      "    pandas.period_range : Return a fixed frequency PeriodIndex.\n",
      "    pandas.interval_range : Return a fixed frequency IntervalIndex.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\n",
      "    exactly three must be specified. If ``freq`` is omitted, the resulting\n",
      "    ``DatetimeIndex`` will have ``periods`` linearly spaced elements between\n",
      "    ``start`` and ``end`` (closed on both sides).\n",
      "    \n",
      "    To learn more about the frequency strings, please see `this link\n",
      "    <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    **Specifying the values**\n",
      "    \n",
      "    The next four examples generate the same `DatetimeIndex`, but vary\n",
      "    the combination of `start`, `end` and `periods`.\n",
      "    \n",
      "    Specify `start` and `end`, with the default daily frequency.\n",
      "    \n",
      "    >>> pd.date_range(start='1/1/2018', end='1/08/2018')\n",
      "    DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n",
      "                   '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08'],\n",
      "                  dtype='datetime64[ns]', freq='D')\n",
      "    \n",
      "    Specify `start` and `periods`, the number of periods (days).\n",
      "    \n",
      "    >>> pd.date_range(start='1/1/2018', periods=8)\n",
      "    DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n",
      "                   '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08'],\n",
      "                  dtype='datetime64[ns]', freq='D')\n",
      "    \n",
      "    Specify `end` and `periods`, the number of periods (days).\n",
      "    \n",
      "    >>> pd.date_range(end='1/1/2018', periods=8)\n",
      "    DatetimeIndex(['2017-12-25', '2017-12-26', '2017-12-27', '2017-12-28',\n",
      "                   '2017-12-29', '2017-12-30', '2017-12-31', '2018-01-01'],\n",
      "                  dtype='datetime64[ns]', freq='D')\n",
      "    \n",
      "    Specify `start`, `end`, and `periods`; the frequency is generated\n",
      "    automatically (linearly spaced).\n",
      "    \n",
      "    >>> pd.date_range(start='2018-04-24', end='2018-04-27', periods=3)\n",
      "    DatetimeIndex(['2018-04-24 00:00:00', '2018-04-25 12:00:00',\n",
      "                   '2018-04-27 00:00:00'],\n",
      "                  dtype='datetime64[ns]', freq=None)\n",
      "    \n",
      "    **Other Parameters**\n",
      "    \n",
      "    Changed the `freq` (frequency) to ``'M'`` (month end frequency).\n",
      "    \n",
      "    >>> pd.date_range(start='1/1/2018', periods=5, freq='M')\n",
      "    DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31', '2018-04-30',\n",
      "                   '2018-05-31'],\n",
      "                  dtype='datetime64[ns]', freq='M')\n",
      "    \n",
      "    Multiples are allowed\n",
      "    \n",
      "    >>> pd.date_range(start='1/1/2018', periods=5, freq='3M')\n",
      "    DatetimeIndex(['2018-01-31', '2018-04-30', '2018-07-31', '2018-10-31',\n",
      "                   '2019-01-31'],\n",
      "                  dtype='datetime64[ns]', freq='3M')\n",
      "    \n",
      "    `freq` can also be specified as an Offset object.\n",
      "    \n",
      "    >>> pd.date_range(start='1/1/2018', periods=5, freq=pd.offsets.MonthEnd(3))\n",
      "    DatetimeIndex(['2018-01-31', '2018-04-30', '2018-07-31', '2018-10-31',\n",
      "                   '2019-01-31'],\n",
      "                  dtype='datetime64[ns]', freq='3M')\n",
      "    \n",
      "    Specify `tz` to set the timezone.\n",
      "    \n",
      "    >>> pd.date_range(start='1/1/2018', periods=5, tz='Asia/Tokyo')\n",
      "    DatetimeIndex(['2018-01-01 00:00:00+09:00', '2018-01-02 00:00:00+09:00',\n",
      "                   '2018-01-03 00:00:00+09:00', '2018-01-04 00:00:00+09:00',\n",
      "                   '2018-01-05 00:00:00+09:00'],\n",
      "                  dtype='datetime64[ns, Asia/Tokyo]', freq='D')\n",
      "    \n",
      "    `closed` controls whether to include `start` and `end` that are on the\n",
      "    boundary. The default includes boundary points on either end.\n",
      "    \n",
      "    >>> pd.date_range(start='2017-01-01', end='2017-01-04', closed=None)\n",
      "    DatetimeIndex(['2017-01-01', '2017-01-02', '2017-01-03', '2017-01-04'],\n",
      "                  dtype='datetime64[ns]', freq='D')\n",
      "    \n",
      "    Use ``closed='left'`` to exclude `end` if it falls on the boundary.\n",
      "    \n",
      "    >>> pd.date_range(start='2017-01-01', end='2017-01-04', closed='left')\n",
      "    DatetimeIndex(['2017-01-01', '2017-01-02', '2017-01-03'],\n",
      "                  dtype='datetime64[ns]', freq='D')\n",
      "    \n",
      "    Use ``closed='right'`` to exclude `start` if it falls on the boundary.\n",
      "    \n",
      "    >>> pd.date_range(start='2017-01-01', end='2017-01-04', closed='right')\n",
      "    DatetimeIndex(['2017-01-02', '2017-01-03', '2017-01-04'],\n",
      "                  dtype='datetime64[ns]', freq='D')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.date_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 날짜로 인덱스 부여하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2016-11-01', '2016-11-02', '2016-11-03'], dtype='datetime64[ns]', name='id', freq='D')\n",
      "[datetime.date(2016, 11, 1) datetime.date(2016, 11, 2)\n",
      " datetime.date(2016, 11, 3)]\n",
      "Int64Index([2016, 2016, 2016], dtype='int64', name='id')\n",
      "Int64Index([11, 11, 11], dtype='int64', name='id')\n",
      "Int64Index([1, 2, 3], dtype='int64', name='id')\n",
      "Int64Index([0, 0, 0], dtype='int64', name='id')\n",
      "Int64Index([0, 0, 0], dtype='int64', name='id')\n",
      "Int64Index([0, 0, 0], dtype='int64', name='id')\n",
      "Int64Index([0, 0, 0], dtype='int64', name='id')\n",
      "Int64Index([0, 0, 0], dtype='int64', name='id')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "id = pd.Index(pd.date_range('2016-11-01',periods=3), name=\"id\")\n",
    "print(id)\n",
    "print(id.date)\n",
    "print(id.year)\n",
    "print(id.month)\n",
    "print(id.day)\n",
    "print(id.hour)\n",
    "print(id.minute)\n",
    "print(id.second)\n",
    "print(id.microsecond)\n",
    "print(id.nanosecond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2016-11-01', '2016-11-02', '2016-11-03'], dtype='period[D]', name='id', freq='D')\n",
      "Int64Index([2016, 2016, 2016], dtype='int64', name='id')\n",
      "Int64Index([11, 11, 11], dtype='int64', name='id')\n",
      "Int64Index([1, 2, 3], dtype='int64', name='id')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "id = pd.Index(pd.period_range('2016-11-01',periods=3), name=\"id\")\n",
    "print(id)\n",
    "\n",
    "print(id.year)\n",
    "print(id.month)\n",
    "print(id.day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reindex로 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-db99c6a79bcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "help(df.reindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리인덱싱해서 처리하면 실제로 추가적인 값이 널로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "obj = pd.Series(['b','a','c'], index=[0,2,4])\n",
    "print(obj)\n",
    "\n",
    "obj1 = obj.reindex(np.arange(6))\n",
    "print(obj1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리인덱싱 할 때 널값에 값을 자동으로 세팅하기  : 앞의 값으로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1 = obj.reindex(np.arange(6), method='ffill')\n",
    "print(obj1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리인덱싱 할 때 널값에 값을 자동으로 세팅하기  : 뒤의 값으로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1 = obj.reindex(np.arange(6), method='bfill')\n",
    "print(obj1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인덱스 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.Series(np.arange(4), \n",
    "                  index=['a','b','c','d'])\n",
    "print(df)\n",
    "print(df.drop(['a','b']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인덱서 클래스 타입 확인하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인덱서를 만든 이유는 실제 판다스는 열 중심으로 처리하는 것이 기준이다. 행을 중심으로 처리하기 위해 별도의 뷰를 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.Series(np.arange(5),index=['a','b','c','d','e'],dtype=np.int_)\n",
    "\n",
    "\n",
    "print(type(a.blocks))\n",
    "#A primarily label-location based indexer, with integer position fallback.\n",
    "print(type(a.ix))\n",
    "#Fast integer location scalar accessor.\n",
    "print(type(a.iat))\n",
    "#Purely integer-location based indexing for selection by position.\n",
    "print(type(a.iloc))\n",
    "\n",
    "#Fast label-based scalar accessor\n",
    "print(type(a.at))\n",
    "#Purely label-location based indexer for selection by label.\n",
    "print(type(a.loc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 시리즈의 데이터 타입을 변경하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.Series(np.arange(5),index=['a','b','c','d','e'],dtype=np.int_)\n",
    "print(a)\n",
    "print(a.astype(np.float_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 뷰를 없애고 새로운 시리즈 객체를 만들기 위해서는 카피를 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.Series([1,1,1,2,2],index=['a','b','c','d','e'],dtype=np.int_)\n",
    "b = a.copy()\n",
    "print(a is b)\n",
    "print(a == b)\n",
    "print(a)\n",
    "print(a.mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인덱스와 값의 정보를 딕셔너리 처리 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 메소드 처리 : keys, iteritems\n",
    "\n",
    "    키는 index 속성의 값을 가져오면 \n",
    "    키와 값은 iteritems 메소드를 이용해서 가져온다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0])\n",
    "print(data.keys())\n",
    "print(data.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.Series([\"aaa\",\"bbb\",\"ccc\",\"ddd\",\"eee\"],index=['a','b','c','d','e'])\n",
    "\n",
    "print(a.iteritems())\n",
    "for i,v in a.iteritems() :\n",
    "    print(i,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시리즈 내부 원소를 조회, 갱신, 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 메소드 처리 : get_value, set_value\n",
    "\n",
    "    내부의 원소 값을 검색하거나 갱신할 때 사용한다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(df.get_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.Series([1,1,1,2,2],index=['a','b','c','d','e'],dtype=np.int_)\n",
    "print(\"element \",a.get_value('a'))\n",
    "print(a.set_value('b',99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 메소드 : 원소 삭제\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(a.pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.Series([\"aaa\",\"bbb\",\"ccc\",\"ddd\",\"eee\"],index=['a','b','c','d','e'])\n",
    "\n",
    "print(a.pop('a'))\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1,2,3,4], name=\"ser1\")\n",
    "\n",
    "print(s)\n",
    "s[0] = 99\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 메소드 : 원소 갱신 update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1,2,3,4], name=\"ser1\")\n",
    "\n",
    "s1 = pd.Series([1,2,3,4], name=\"ser2\")\n",
    "\n",
    "d = {s.name : s.values}\n",
    "d.update({s1.name : s1.values})\n",
    "print(d)\n",
    "\n",
    "p = pd.DataFrame(d)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시리즈 데이터를 이용해서 그래프 그리기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Series를 이용해서 matplotlib 그래프 그리기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "s = pd.Series([1,2,3,4], name=\"ser1\")\n",
    "\n",
    "s1 = pd.Series([1,2,3,4], name=\"ser2\")\n",
    "print(s)\n",
    "print(s1)\n",
    "plt.plot(s,s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "c1 = pd.Series([603105,-405885,283715,365410, 302876, 393534], name='foreigner')\n",
    "print(c1)\n",
    "\n",
    "del c1[1]\n",
    "\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인덱싱 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  정보 검색  및 index 속성을  이용한 검색\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([0,1,2,3,4])\n",
    "\n",
    "s1 = pd.Series([0,1,2,3,4], index=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "\n",
    "print(s.index)\n",
    "print(s[0])\n",
    "print(s1.index)\n",
    "print(s1['a'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 속성을 index 속성 내의 값을 조회하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1,2,3,4], name=\"ser1\")\n",
    "print(type(s))\n",
    "print(s.values)\n",
    "print(type(s.values))\n",
    "print(s.axes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 슬라이싱 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  정수 슬라이싱 검색 및 index 속성을 이용한 슬라이싱 검색\n",
    "\n",
    "    index 속성을 이용한 검색은 마지막도 포함해서 처리됨\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "s = pd.Series([0,1,2,3,4])\n",
    "\n",
    "s1 = pd.Series([0,1,2,3,4], index=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "print(s[0:3])\n",
    "print(s1['a':'c'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Fancy 검색을 이용\n",
    "\n",
    "    정수와 index 속성 그리고 논리식의 결과가 배열로 처리되고 이를 직접 넣어 검색 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "s = pd.Series([0,1,2,3,4])\n",
    "\n",
    "s1 = pd.Series([0,1,2,3,4], index=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "print(s[[4,3,1]])\n",
    "print(s1[['d','a','c']])\n",
    "\n",
    "print(s1[ s1 < 3 ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### key 값이 없을 경우 예외가 발생한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'a':1,'b':2,'c':3}\n",
    "s2 = pd.Series(d)\n",
    "print(s2)\n",
    "\n",
    "print(s2['d'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 없는 키를 처리하기 위해 get 메소드를 제공한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'a':1,'b':2,'c':3}\n",
    "s2 = pd.Series(d)\n",
    "print(s2)\n",
    "\n",
    "print(s2.get(\"d\", \"defaults\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 멀티인덱스를 이용한 검색처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiindex 사용시 검색\n",
    "\n",
    "    인덱스 순서에 따라 검색이 가능하다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],\n",
    "           ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n",
    "           \n",
    "tuples = list(zip(*arrays))\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "\n",
    "s = pd.Series(np.random.randn(8), index=index)\n",
    "print(s)\n",
    "\n",
    "print(s['bar'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s['bar','one']) # 첫번째와 두번째 인덱스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연산처리 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  산술연산 \n",
    "\n",
    "    스칼라 값일 경우는 브로드캐스팅이 발생해서 처리된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "d = {'a':1,'b':2,'c':3}\n",
    "s2 = pd.Series(d)\n",
    "print(s2 + 1)\n",
    "print(s2 - 1)\n",
    "print(s2 * 3)\n",
    "print(s2 / 2)\n",
    "print(s2 // 2)\n",
    "print(s2 % 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 산술 연산시  원소의 개수가 맞지 않으면 nan으로 처리됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "d = {'a':1,'b':2,'c':3}\n",
    "s2 = pd.Series(d)\n",
    "\n",
    "print(s2 + s2)\n",
    "print(s2 + s2[0:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### series 객체간 연산에서는 개수가 맞지 않아도 처리된다.\n",
    "\n",
    "    부족한 부분은 NaN으로 처리된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "obj2 = pd.Series([1,2,3,4])\n",
    "obj3 = pd.Series([5,6,7,8,10])\n",
    "print(obj2+obj3)\n",
    "print(obj2-obj3)\n",
    "print(obj2*obj3)\n",
    "print(obj2/obj3)\n",
    "print(obj2//obj3)\n",
    "print(obj2%obj3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 논리 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(pd.Series([True]).bool())\n",
    "print(pd.Series([False]).bool())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0])\n",
    "\n",
    "\n",
    "print((data+data).equals(data*2))\n",
    "print((data+data) == (data*2))\n",
    "print(((data+data) == (data*2)).all())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0])\n",
    "\n",
    "print((data+data) == (data*2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0])\n",
    "print((data>0.5).all())\n",
    "print((data>0.5).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0])\n",
    "\n",
    "print((data == data).all())\n",
    "print((data+data != data).all())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계 처리 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  평균, 중앙값, 분산, 표준편차 구하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0])\n",
    "print(data.sum(), data.sum()/len(data))\n",
    "print(\" average \",data.mean())\n",
    "print(\" median \",data.median())\n",
    "print(\" var \",data.var())\n",
    "\n",
    "print(\" standard deviation \",data.std())\n",
    "print(\"      \", math.sqrt(data.var()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특정 상단과 하단 정보 조회"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  특정 상단 위치와 하단 위치 부분 조회 : head, tail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "long_series = pd.Series(np.random.randn(15))\n",
    "print(long_series.head())\n",
    "print(long_series.tail())\n",
    "print(long_series.head(n=7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series(np.array([\"aaa\",\"bbb\",\"ccc\",\"ddd\",\"eee\",'fff']))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
